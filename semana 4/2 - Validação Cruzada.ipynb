{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d47031d-a459-4cbf-8374-fbb8835549d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f166a-1d40-4874-86cf-b3946678e6fd",
   "metadata": {},
   "source": [
    "# Validação Cruzada\n",
    "\n",
    "A validação cruzada é um meta-protocolo que combina métricas de predição de conjuntos de teste obtidas a partir do mesmo modelo de aprendizagem de máquina sobre diferentes partições da base de dados. As métricas são normalmente combinadas usando medidas estatísticas como média e desvio padrão, que representam uma estimativa do desempenho do modelo em dados que não foram utilizadas para treinar o modelo. Estas medidas podem ser usadas em testes estatísticos para selecionar o melhor modelo para usar na prática. Um dos protocolos de validação cruzada mais amplamente utilizados é a *validação cruzada em k-vias*.\n",
    "\n",
    "## Validação Cruzada em k-vias (*K-fold cross validation*)\n",
    "\n",
    "Com a validação cruzada em k-vias, a base de dados é aleatoriamente particionada em $k$ subconjuntos, todos aproximadamente contendo a mesma quantidade de elementos. Opcionalmente, os dados podem ser embaralhados e o particionamento pode ser feito de forma estratificada. Cada subconjunto é conhecido como uma **via** ou **pasta** (em inglês: ***fold***). $k$ particionamentos em conjuntos de treino e teste são criados. Em cada particionamento, o conjunto de teste assume uma única via, e o restante das $k-1$ vias são usadas como conjunto de treinamento. Cada particionamento utiliza uma via diferente como conjunto de teste, e cada conjunto de teste é utilizado apenas uma única vez durante o procedimento. Desta forma, todss os instâncias da base de dados são utilizadas para avaliar o modelo e cada instância é usada uma única vez. A Figura abaixo mostra um esquema dos particionamentos realizados com validação cruzada em 4 vias ($k=4$).\n",
    "\n",
    "<center><img src='kfold-cv.jpg'></img></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ac4aec-efad-4085-8370-7f4a40706737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_iris(as_frame=True)\n",
    "df = ds.frame\n",
    "X = ds.data.values\n",
    "y = ds.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42b670-92df-4cd2-bf57-71223fec0f42",
   "metadata": {},
   "source": [
    "Vamos fazer a otimização do hiperparâmetro $k$ do KNN, como na última aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3f9e5e-4d35-4685-8acb-c2eb8d863b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecionar_melhor_k(ks, X_treino, X_val, y_treino, y_val):\n",
    "    acuracias_val = []\n",
    "\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_treino, y_treino)\n",
    "        pred = knn.predict(X_val)\n",
    "        acuracias_val.append(accuracy_score(y_val, pred))\n",
    "        \n",
    "    melhor_val = max(acuracias_val)\n",
    "    melhor_k = ks[np.argmax(acuracias_val)]        \n",
    "    knn = KNeighborsClassifier(n_neighbors=melhor_k)\n",
    "    knn.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "    \n",
    "    return knn, melhor_k, melhor_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bccc3a-09f8-457c-80a3-60cb31ea18c8",
   "metadata": {},
   "source": [
    "A biblioteca sklearn oferece vários protocolos de validação cruzada. O código a seguir mostra como usar a validação cruzada estratificada (implementada na classe ``StratifiedKFold`` do módulo ``model_selection``). O método ``split`` gera os índices das instâncias que devem ser usadas para treinamente e teste, respectivamente. Esta class faz o particionamento estratificado, ou seja, procura manter as proporções das instâncias entre as classes da base de dados toda nos conjuntos de treinamento e teste.\n",
    "\n",
    "Não existe um número certo de vias que devemos dividir a base de dados para realizar a validação cruzada. Entretanto, é comum dividir a base de dados em 10 vias. Note no código abaixo que usamos ``n_splits=10``, que instrui o sklearn a fazer o particionamento em 10 vias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3824744d-82ec-4029-b657-3e5da80bc9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.87, max: 1.00, avg +- std: 0.94+-0.05\n"
     ]
    }
   ],
   "source": [
    "#a validação cruzada será realizada em 10 vias.\n",
    "k_vias = 10\n",
    "\n",
    "#usar o protocolo de validação cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=k_vias, shuffle=True, random_state=1)\n",
    "\n",
    "acuracias = []\n",
    "\n",
    "#a função split retorna os índices das instâncias que devem ser usadas para o treinamento e o teste.\n",
    "for idx_treino, idx_teste in skf.split(X, y):\n",
    "    \n",
    "    #extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "    X_treino = X[idx_treino]\n",
    "    y_treino = y[idx_treino]\n",
    "    \n",
    "    #extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "    X_teste = X[idx_teste]\n",
    "    y_teste = y[idx_teste]\n",
    "    \n",
    "    #separar as instâncias de treinamento entre treinamento e validação para a otimização do hiperparâmetro k\n",
    "    X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.2, stratify=y_treino, shuffle=True, random_state=1)\n",
    "    \n",
    "    #colocar todas as variáveis na mesma escala, usando o conjunto de treinamento para calcular os parâmetros da escala\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_treino)\n",
    "    X_treino = ss.transform(X_treino)\n",
    "    X_teste = ss.transform(X_teste)\n",
    "    X_val = ss.transform(X_val)\n",
    "\n",
    "    #escolher o k com o melhor resultado no conjunto de validação e treinar o KNN com o melhor k.\n",
    "    knn, _, _ = selecionar_melhor_k(range(1,30,2), X_treino, X_val, y_treino, y_val)\n",
    "    \n",
    "    #calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "    acuracias.append(accuracy_score(y_teste, knn.predict(X_teste)))\n",
    "    \n",
    "#calcular as estatísticas da validação cruzada. Estas estatísticas nos dão uma confiança que, na média, este é o desempenho esperado\n",
    "#do classificador no mundo real.\n",
    "print(\"min: %.2f, max: %.2f, avg +- std: %.2f+-%.2f\" % (min(acuracias), max(acuracias), np.mean(acuracias), np.std(acuracias)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3a356-4262-41c0-b223-b5b9ec5b56e7",
   "metadata": {},
   "source": [
    "O resultado obtido no exemplo anterior nos diz que podemos esperar que nosso classificador acerte entre 89% e 99% dos casos no mundo real.\n",
    "\n",
    "Veja que no exemplo anterior usamos um único conjunto de validação para otimizar o valor de $k$ em cada iteração da validação cruzada. Uma alternativa é usar validação cruzada em k-vias no conjunto de treinamento para obter uma estimativa da melhor combinação de parâmetros na via de validação. Desta forma, teremos uma validação cruzada em dois níveis: no nível \"de fora\" teremos a validação cruzada em k-vias para avaliar os $k_1$ particionamentos da base de dados. No nível \"de dentro\" teremos a validação cruzada em $k_2$ vias para avaliar cada combinação de parâmetros no conjunto de treinamento atual, particionando-o em $k_2$ vias de validação. O código abaixo representa este procedimento.\n",
    "\n",
    "A biblioteca *sklearn* oferece a validação cruzada para a otimização de hiperparâmetros por busca exaustiva pela classe ``GridSearchCV`` do módulo ``model_selection``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516db939-e7b0-42d7-94a7-284802272dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.87, max: 1.00, avg +- std: 0.95+-0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV #busca exaustiva para otimização de hiperparâmetro por validação cruzada\n",
    "\n",
    "k1 = 10 #controla o número de vias da validação cruzada para estimar o desempenho do modelo\n",
    "k2 = 10 #controla o número de vida da validação cruzada para otimização de hiperparametros\n",
    "\n",
    "#usar o protocolo de validação cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=k1, shuffle=True, random_state=1)\n",
    "\n",
    "acuracias = []\n",
    "\n",
    "#a função split retorna os índices das instâncias que devem ser usadas para o treinamento e o teste.\n",
    "for idx_treino, idx_teste in skf.split(X, y):\n",
    "    \n",
    "    #extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "    X_treino = X[idx_treino]\n",
    "    y_treino = y[idx_treino]\n",
    "    \n",
    "    #extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "    X_teste = X[idx_teste]\n",
    "    y_teste = y[idx_teste]\n",
    "    \n",
    "    #colocar todas as variáveis na mesma escala, usando o conjunto de treinamento para calcular os parâmetros da escala\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_treino)\n",
    "    X_treino = ss.transform(X_treino)\n",
    "    X_teste = ss.transform(X_teste)\n",
    "    \n",
    "    #combinações de parametros otimizar. Aqui estamos apenas otimizando o número de vizinhos mais próximos para o knn (k).\n",
    "    #Entretanto, podemos colocar todos os valores de todos os parametros. O sklearn se encarrega de gerar todas as combinações.\n",
    "    params = {'n_neighbors' : range(1,30,2)}\n",
    "    #instanciar um KNN com parametros padrão\n",
    "    knn = KNeighborsClassifier()\n",
    "    #instanciar um GridSearchCV com k2 vias.\n",
    "    knn = GridSearchCV(knn, params, cv=StratifiedKFold(n_splits=k2))\n",
    "    #realizar a otimização dos hiperparâmetros e treinar o modelo final com a melhor combinação de hiperparametros com todos os dados de treinamento\n",
    "    knn.fit(X_treino, y_treino)\n",
    "    \n",
    "    #calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "    acuracias.append(accuracy_score(y_teste, knn.predict(X_teste)))\n",
    "    \n",
    "#calcular as estatísticas da validação cruzada. Estas estatísticas nos dão uma confiança que, na média, este é o desempenho esperado\n",
    "#do classificador no mundo real.\n",
    "print(\"min: %.2f, max: %.2f, avg +- std: %.2f+-%.2f\" % (min(acuracias), max(acuracias), np.mean(acuracias), np.std(acuracias)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148706b-bfd8-4b24-ae15-cb4e71bd24e7",
   "metadata": {},
   "source": [
    "Note que houve uma pequena diferença na média dos resultados ao escolhermos o valor de $k$ usando validação cruzada. Por outro lado, notamos que o treinamento e validação do modelo nos particionamentos diferentes demora bem mais tempo. A escolha entre fazer a validação cruzada para a seleção dos hiperparâmetros ou apenas um único particionamento do conjunto de treino em treino e validação fica a critério do projetista do sistema, podendo ou não fazer muita diferença no resultado final.\n",
    "\n",
    "Em resumo, as estatísticas obtidas com a validação cruzada sobre os diferentes particionamentos da base de dados nos dão uma idéia do desempenho do classificador (modelo) na prática. Portanto, estas estatísticas podem ser usadas para comparar os resultados esperados de modelos diferentes que foram projetados para resolver o mesmo problema. Estas estatísticas nos permitem fazer a escolha do modelo que mais provavelmente será melhor na prática. Para isso podemos usar testes estatísticos. Estudaremos um teste amplamente utilizado neste contexto em breve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce7d55-6c32-4ebc-8a47-86c0e8fd658c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
